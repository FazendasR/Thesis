{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0f59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add6b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted reference data saved to C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === Paths ===\n",
    "json_input_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\generation_evaluation_dataset.json\"\n",
    "ref_xlsx_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data.xlsx\"\n",
    "gen_xlsx_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\rag_no_prompting_medium_Mistral_results.xlsx\"\n",
    "final_output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_hard.json\"\n",
    "\n",
    "### === STEP 1: Extract from JSON to XLSX ===\n",
    "\n",
    "with open(json_input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Grab first 29 items only\n",
    "records = data[\"evaluation_generation_dataset\"][:29]\n",
    "\n",
    "ref_data = {\n",
    "    \"reference_answer\": [entry[\"reference_answer\"][0] if entry[\"reference_answer\"] else \"\" for entry in records],\n",
    "    \"relevant_docs\": [\", \".join(entry[\"relevant_docs\"]) for entry in records]\n",
    "}\n",
    "\n",
    "ref_df = pd.DataFrame(ref_data)\n",
    "ref_df.to_excel(ref_xlsx_path, index=False)\n",
    "print(f\"✅ Extracted reference data saved to {ref_xlsx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7872e1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final JSON file with 50 entries saved to: C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_hard.json\n"
     ]
    }
   ],
   "source": [
    "### === STEP 2: Recombine all into final JSON ===\n",
    "\n",
    "# Load 50 question-generated_answer pairs\n",
    "gen_df = pd.read_excel(gen_xlsx_path, engine=\"openpyxl\", skiprows=1, usecols=[0, 1], nrows=50)\n",
    "gen_df.columns = [\"question\", \"generated_answer\"]\n",
    "gen_df.fillna(\"\", inplace=True)\n",
    "\n",
    "# Load reference answers and docs (29 rows)\n",
    "ref_df = pd.read_excel(ref_xlsx_path)\n",
    "ref_df.fillna(\"\", inplace=True)\n",
    "\n",
    "final_entries = []\n",
    "\n",
    "for idx in range(len(gen_df)):\n",
    "    question = gen_df.loc[idx, \"question\"]\n",
    "    generated_answer = gen_df.loc[idx, \"generated_answer\"]\n",
    "\n",
    "    if idx < len(ref_df):\n",
    "        reference_answer = [ref_df.loc[idx, \"reference_answer\"]]\n",
    "        relevant_docs = [doc.strip() for doc in str(ref_df.loc[idx, \"relevant_docs\"]).split(\",\")]\n",
    "    else:\n",
    "        reference_answer = [\"\"]\n",
    "        relevant_docs = [\"\"]\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"relevant_docs\": relevant_docs,\n",
    "        \"reference_answer\": reference_answer,\n",
    "        \"generated_answer\": [generated_answer],\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    final_entries.append(entry)\n",
    "\n",
    "# Save to final JSON\n",
    "with open(final_output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"evaluation_generation_dataset_mistral_hard\": final_entries}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Final JSON file with 50 entries saved to: {final_output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efa813",
   "metadata": {},
   "source": [
    "# Generating the evaluation datasets.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d995255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load Excel file\n",
    "excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\rag_no_prompting_medium_Mistral_results.xlsx\"\n",
    "df = pd.read_excel(excel_file, engine=\"openpyxl\")\n",
    "\n",
    "# Initialize result structure\n",
    "json_data = {\n",
    "    \"evaluation_generation_dataset_mistral_hard\": []\n",
    "}\n",
    "\n",
    "# Helper function to split \"Document 1: ... Document 2: ...\" into two parts\n",
    "def split_documents(text):\n",
    "    doc1_match = re.search(r\"Document 1:\\s*(.*?)(?:Document 2:|$)\", text, re.DOTALL)\n",
    "    doc2_match = re.search(r\"Document 2:\\s*(.*)\", text, re.DOTALL)\n",
    "    doc1 = doc1_match.group(1).strip() if doc1_match else \"\"\n",
    "    doc2 = doc2_match.group(1).strip() if doc2_match else \"\"\n",
    "    return [doc1, doc2]\n",
    "\n",
    "# Iterate through each row (starting from index 0 which corresponds to Excel row 2)\n",
    "for idx, row in df.iterrows():\n",
    "    question = str(row['question']).strip()\n",
    "    generated_answer = [str(row['generated_answer']).strip()]\n",
    "    reference_docs = split_documents(str(row['retrieved_documents']))\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"relevant_docs\": reference_docs,\n",
    "        \"reference_answer\": [\"\"],  # Assuming blank for now\n",
    "        \"generated_answer\": generated_answer,\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    json_data[\"evaluation_generation_dataset_mistral_hard\"].append(entry)\n",
    "\n",
    "# Write to JSON file\n",
    "output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_no_prompting_hard.json\"\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ JSON file generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158b43f",
   "metadata": {},
   "source": [
    "### Combining also the reference answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e8443",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'retrieved_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1176153\\Downloads\\github\\Thesis\\thesis_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'retrieved_documents'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m question = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]).strip()\n\u001b[32m     30\u001b[39m generated_answer = [\u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mgenerated_answer\u001b[39m\u001b[33m'\u001b[39m]).strip()]\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m reference_docs = split_documents(\u001b[38;5;28mstr\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mretrieved_documents\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Reference answer from ref_data.xlsx (assumed to be in column 'reference_answer')\u001b[39;00m\n\u001b[32m     34\u001b[39m reference_answer = [\u001b[38;5;28mstr\u001b[39m(df_ref.iloc[idx][\u001b[33m'\u001b[39m\u001b[33mreference_answer\u001b[39m\u001b[33m'\u001b[39m]).strip()] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mreference_answer\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ref.columns \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1176153\\Downloads\\github\\Thesis\\thesis_env\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1176153\\Downloads\\github\\Thesis\\thesis_env\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1176153\\Downloads\\github\\Thesis\\thesis_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'retrieved_documents'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Paths to input and output files\n",
    "main_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\mistral_no_rag_results_easy.xlsx\"\n",
    "ref_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data.xlsx\"\n",
    "output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_no_prompting_hard.json\"\n",
    "\n",
    "# Load Excel files\n",
    "df_main = pd.read_excel(main_excel_file, engine=\"openpyxl\")\n",
    "df_ref = pd.read_excel(ref_excel_file, engine=\"openpyxl\")\n",
    "\n",
    "# Initialize result structure\n",
    "json_data = {\n",
    "    \"evaluation_generation_dataset_mistral_hard\": []\n",
    "}\n",
    "\n",
    "# Helper function to split \"Document 1: ... Document 2: ...\" into two parts\n",
    "def split_documents(text):\n",
    "    doc1_match = re.search(r\"Document 1:\\s*(.*?)(?:Document 2:|$)\", text, re.DOTALL)\n",
    "    doc2_match = re.search(r\"Document 2:\\s*(.*)\", text, re.DOTALL)\n",
    "    doc1 = doc1_match.group(1).strip() if doc1_match else \"\"\n",
    "    doc2 = doc2_match.group(1).strip() if doc2_match else \"\"\n",
    "    return [doc1, doc2]\n",
    "\n",
    "# Iterate through each row (assuming both files have same number/order of rows)\n",
    "for idx, row in df_main.iterrows():\n",
    "    question = str(row['question']).strip()\n",
    "    generated_answer = [str(row['generated_answer']).strip()]\n",
    "    reference_docs = split_documents(str(row['retrieved_documents']))\n",
    "\n",
    "    # Reference answer from ref_data.xlsx (assumed to be in column 'reference_answer')\n",
    "    reference_answer = [str(df_ref.iloc[idx]['reference_answer']).strip()] if 'reference_answer' in df_ref.columns else [\"\"]\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"relevant_docs\": reference_docs,\n",
    "        \"reference_answer\": reference_answer,\n",
    "        \"generated_answer\": generated_answer,\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    json_data[\"evaluation_generation_dataset_mistral_hard\"].append(entry)\n",
    "\n",
    "# Write to JSON\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ JSON file with reference answers generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa99d5",
   "metadata": {},
   "source": [
    "### No RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b5ab0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m question = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]).strip()\n\u001b[32m     21\u001b[39m generated_answer = [\u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mgenerated_answer\u001b[39m\u001b[33m'\u001b[39m]).strip()]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m reference_answer = [\u001b[38;5;28mstr\u001b[39m(\u001b[43mdf_ref\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mreference_answer\u001b[39m\u001b[33m'\u001b[39m]).strip()] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mreference_answer\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_ref.columns \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     24\u001b[39m entry = {\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: idx + \u001b[32m1\u001b[39m,\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhuman_score\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m\n\u001b[32m     30\u001b[39m }\n\u001b[32m     31\u001b[39m json_data[\u001b[33m\"\u001b[39m\u001b[33mevaluation_generation_dataset_mistral_no_rag_results_easy\u001b[39m\u001b[33m\"\u001b[39m].append(entry)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1176153\\Downloads\\github\\Thesis\\thesis_env\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1176153\\Downloads\\github\\Thesis\\thesis_env\\Lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index by location index with a non-integer key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1751\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1752\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._ixs(key, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1176153\\Downloads\\github\\Thesis\\thesis_env\\Lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[39m, in \u001b[36m_iLocIndexer._validate_integer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1683\u001b[39m len_axis = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj._get_axis(axis))\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key >= len_axis \u001b[38;5;129;01mor\u001b[39;00m key < -len_axis:\n\u001b[32m-> \u001b[39m\u001b[32m1685\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msingle positional indexer is out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Paths to input and output files\n",
    "main_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\mistral_no_rag_results_easy.xlsx\"\n",
    "ref_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data.xlsx\"\n",
    "output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_no_rag_results_easy.xlsx.json\"\n",
    "\n",
    "# Load Excel files\n",
    "df_main = pd.read_excel(main_excel_file, engine=\"openpyxl\")\n",
    "df_ref = pd.read_excel(ref_excel_file, engine=\"openpyxl\")\n",
    "\n",
    "# Initialize result structure\n",
    "json_data = {\n",
    "    \"evaluation_generation_dataset_mistral_no_rag_results_easy\": []\n",
    "}\n",
    "\n",
    "# Iterate through each row (assuming both files have same number/order of rows)\n",
    "for idx, row in df_main.iterrows():\n",
    "    question = str(row['question']).strip()\n",
    "    generated_answer = [str(row['generated_answer']).strip()]\n",
    "    reference_answer = [str(df_ref.iloc[idx]['reference_answer']).strip()] if 'reference_answer' in df_ref.columns else [\"\"]\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"reference_answer\": reference_answer,\n",
    "        \"generated_answer\": generated_answer,\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    json_data[\"evaluation_generation_dataset_mistral_no_rag_results_easy\"].append(entry)\n",
    "\n",
    "# Write to JSON\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ JSON file without retrieval data generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2718bba",
   "metadata": {},
   "source": [
    "# Generate word doc with truth answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54cd2c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Word document saved to: C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\combined_output.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Paths\n",
    "excel_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\rag_zero_shot_prompting_medium_Mistral_results.xlsx\"\n",
    "word_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\combined_output.docx\"\n",
    "\n",
    "# Load Excel\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Create Word document\n",
    "doc = Document()\n",
    "\n",
    "# Iterate rows\n",
    "for idx, row in df.iterrows():\n",
    "    question = str(row['A']) if 'A' in df.columns else str(row.iloc[0])\n",
    "    retrieved_docs = str(row['C']) if 'C' in df.columns else str(row.iloc[2])\n",
    "\n",
    "    # Add question as heading\n",
    "    doc.add_heading(f\"Question {idx + 1}:\", level=2)\n",
    "    doc.add_paragraph(question)\n",
    "\n",
    "    # Add retrieved documents as normal text\n",
    "    doc.add_heading(\"Retrieved Documents:\", level=3)\n",
    "    doc.add_paragraph(retrieved_docs)\n",
    "\n",
    "    # Add a line break for readability\n",
    "    doc.add_paragraph(\"\\n---\\n\")\n",
    "\n",
    "# Save Word file\n",
    "doc.save(word_path)\n",
    "\n",
    "print(f\"Combined Word document saved to: {word_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda44b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
