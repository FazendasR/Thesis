{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0f59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add6b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted reference data saved to C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === Paths ===\n",
    "json_input_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\generation_evaluation_dataset.json\"\n",
    "ref_xlsx_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data.xlsx\"\n",
    "gen_xlsx_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\rag_no_prompting_medium_Mistral_results.xlsx\"\n",
    "final_output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_hard.json\"\n",
    "\n",
    "### === STEP 1: Extract from JSON to XLSX ===\n",
    "\n",
    "with open(json_input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Grab first 29 items only\n",
    "records = data[\"evaluation_generation_dataset\"][:29]\n",
    "\n",
    "ref_data = {\n",
    "    \"reference_answer\": [entry[\"reference_answer\"][0] if entry[\"reference_answer\"] else \"\" for entry in records],\n",
    "    \"relevant_docs\": [\", \".join(entry[\"relevant_docs\"]) for entry in records]\n",
    "}\n",
    "\n",
    "ref_df = pd.DataFrame(ref_data)\n",
    "ref_df.to_excel(ref_xlsx_path, index=False)\n",
    "print(f\"✅ Extracted reference data saved to {ref_xlsx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7872e1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final JSON file with 50 entries saved to: C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_hard.json\n"
     ]
    }
   ],
   "source": [
    "### === STEP 2: Recombine all into final JSON ===\n",
    "\n",
    "# Load 50 question-generated_answer pairs\n",
    "gen_df = pd.read_excel(gen_xlsx_path, engine=\"openpyxl\", skiprows=1, usecols=[0, 1], nrows=50)\n",
    "gen_df.columns = [\"question\", \"generated_answer\"]\n",
    "gen_df.fillna(\"\", inplace=True)\n",
    "\n",
    "# Load reference answers and docs (29 rows)\n",
    "ref_df = pd.read_excel(ref_xlsx_path)\n",
    "ref_df.fillna(\"\", inplace=True)\n",
    "\n",
    "final_entries = []\n",
    "\n",
    "for idx in range(len(gen_df)):\n",
    "    question = gen_df.loc[idx, \"question\"]\n",
    "    generated_answer = gen_df.loc[idx, \"generated_answer\"]\n",
    "\n",
    "    if idx < len(ref_df):\n",
    "        reference_answer = [ref_df.loc[idx, \"reference_answer\"]]\n",
    "        relevant_docs = [doc.strip() for doc in str(ref_df.loc[idx, \"relevant_docs\"]).split(\",\")]\n",
    "    else:\n",
    "        reference_answer = [\"\"]\n",
    "        relevant_docs = [\"\"]\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"relevant_docs\": relevant_docs,\n",
    "        \"reference_answer\": reference_answer,\n",
    "        \"generated_answer\": [generated_answer],\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    final_entries.append(entry)\n",
    "\n",
    "# Save to final JSON\n",
    "with open(final_output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"evaluation_generation_dataset_mistral_hard\": final_entries}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Final JSON file with 50 entries saved to: {final_output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efa813",
   "metadata": {},
   "source": [
    "# Generating the evaluation datasets.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d995255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load Excel file\n",
    "excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\rag_no_prompting_medium_Mistral_results.xlsx\"\n",
    "df = pd.read_excel(excel_file, engine=\"openpyxl\")\n",
    "\n",
    "# Initialize result structure\n",
    "json_data = {\n",
    "    \"evaluation_generation_dataset_mistral_hard\": []\n",
    "}\n",
    "\n",
    "# Helper function to split \"Document 1: ... Document 2: ...\" into two parts\n",
    "def split_documents(text):\n",
    "    doc1_match = re.search(r\"Document 1:\\s*(.*?)(?:Document 2:|$)\", text, re.DOTALL)\n",
    "    doc2_match = re.search(r\"Document 2:\\s*(.*)\", text, re.DOTALL)\n",
    "    doc1 = doc1_match.group(1).strip() if doc1_match else \"\"\n",
    "    doc2 = doc2_match.group(1).strip() if doc2_match else \"\"\n",
    "    return [doc1, doc2]\n",
    "\n",
    "# Iterate through each row (starting from index 0 which corresponds to Excel row 2)\n",
    "for idx, row in df.iterrows():\n",
    "    question = str(row['question']).strip()\n",
    "    generated_answer = [str(row['generated_answer']).strip()]\n",
    "    reference_docs = split_documents(str(row['retrieved_documents']))\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"relevant_docs\": reference_docs,\n",
    "        \"reference_answer\": [\"\"],  # Assuming blank for now\n",
    "        \"generated_answer\": generated_answer,\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    json_data[\"evaluation_generation_dataset_mistral_hard\"].append(entry)\n",
    "\n",
    "# Write to JSON file\n",
    "output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_mistral_no_prompting_hard.json\"\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ JSON file generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158b43f",
   "metadata": {},
   "source": [
    "### Combining also the reference answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4e8443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file with reference answers generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Paths to input and output files\n",
    "main_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\rag_no_prompting_easy_Llama1B_results.xlsx\"\n",
    "ref_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data_easy_questions.xlsx\"\n",
    "output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_Llama1B_no_prompting_easy.json\"\n",
    "\n",
    "# Load Excel files\n",
    "df_main = pd.read_excel(main_excel_file, engine=\"openpyxl\")\n",
    "df_ref = pd.read_excel(ref_excel_file, engine=\"openpyxl\")\n",
    "\n",
    "# Initialize result structure\n",
    "json_data = {\n",
    "    \"evaluation_generation_dataset_mistral_hard\": []\n",
    "}\n",
    "\n",
    "# Helper function to split \"Document 1: ... Document 2: ...\" into two parts\n",
    "def split_documents(text):\n",
    "    doc1_match = re.search(r\"Document 1:\\s*(.*?)(?:Document 2:|$)\", text, re.DOTALL)\n",
    "    doc2_match = re.search(r\"Document 2:\\s*(.*)\", text, re.DOTALL)\n",
    "    doc1 = doc1_match.group(1).strip() if doc1_match else \"\"\n",
    "    doc2 = doc2_match.group(1).strip() if doc2_match else \"\"\n",
    "    return [doc1, doc2]\n",
    "\n",
    "# Iterate through each row (assuming both files have same number/order of rows)\n",
    "for idx, row in df_main.iterrows():\n",
    "    question = str(row['question']).strip()\n",
    "    generated_answer = [str(row['generated_answer']).strip()]\n",
    "    reference_docs = split_documents(str(row['retrieved_documents']))\n",
    "\n",
    "    # Reference answer from ref_data.xlsx (assumed to be in column 'reference_answer')\n",
    "    reference_answer = [str(df_ref.iloc[idx]['reference_answer']).strip()] if 'reference_answer' in df_ref.columns else [\"\"]\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"relevant_docs\": reference_docs,\n",
    "        \"reference_answer\": reference_answer,\n",
    "        \"generated_answer\": generated_answer,\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    json_data[\"evaluation_generation_dataset_mistral_hard\"].append(entry)\n",
    "\n",
    "# Write to JSON\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ JSON file with reference answers generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa99d5",
   "metadata": {},
   "source": [
    "### No RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b5ab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file without retrieval data generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Paths to input and output files\n",
    "main_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\Llama1B_no_rag_results_easy.xlsx\"\n",
    "ref_excel_file = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\ref_data_easy_questions.xlsx\"\n",
    "output_json_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\data\\Preprocessing_text\\evaluation_generation_dataset_Llama1B_no_rag_results_easy.json\"\n",
    "\n",
    "# Load Excel files\n",
    "df_main = pd.read_excel(main_excel_file, engine=\"openpyxl\")\n",
    "df_ref = pd.read_excel(ref_excel_file, engine=\"openpyxl\")\n",
    "\n",
    "# Initialize result structure\n",
    "json_data = {\n",
    "    \"evaluation_generation_dataset_mistral_no_rag_results_easy\": []\n",
    "}\n",
    "\n",
    "# Iterate through each row (assuming both files have same number/order of rows)\n",
    "for idx, row in df_main.iterrows():\n",
    "    question = str(row['question']).strip()\n",
    "    generated_answer = [str(row['generated_answer']).strip()]\n",
    "    reference_answer = [str(df_ref.iloc[idx]['reference_answer']).strip()] if 'reference_answer' in df_ref.columns else [\"\"]\n",
    "\n",
    "    entry = {\n",
    "        \"id\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"reference_answer\": reference_answer,\n",
    "        \"generated_answer\": generated_answer,\n",
    "        \"human_score\": 0\n",
    "    }\n",
    "    json_data[\"evaluation_generation_dataset_mistral_no_rag_results_easy\"].append(entry)\n",
    "\n",
    "# Write to JSON\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ JSON file without retrieval data generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2718bba",
   "metadata": {},
   "source": [
    "# Generate word doc with truth answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54cd2c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Word document saved to: C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\combined_output.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Paths\n",
    "excel_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\rag_zero_shot_prompting_medium_Mistral_results.xlsx\"\n",
    "word_path = r\"C:\\Users\\1176153\\Downloads\\github\\Thesis\\model\\src\\combined_output.docx\"\n",
    "\n",
    "# Load Excel\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Create Word document\n",
    "doc = Document()\n",
    "\n",
    "# Iterate rows\n",
    "for idx, row in df.iterrows():\n",
    "    question = str(row['A']) if 'A' in df.columns else str(row.iloc[0])\n",
    "    retrieved_docs = str(row['C']) if 'C' in df.columns else str(row.iloc[2])\n",
    "\n",
    "    # Add question as heading\n",
    "    doc.add_heading(f\"Question {idx + 1}:\", level=2)\n",
    "    doc.add_paragraph(question)\n",
    "\n",
    "    # Add retrieved documents as normal text\n",
    "    doc.add_heading(\"Retrieved Documents:\", level=3)\n",
    "    doc.add_paragraph(retrieved_docs)\n",
    "\n",
    "    # Add a line break for readability\n",
    "    doc.add_paragraph(\"\\n---\\n\")\n",
    "\n",
    "# Save Word file\n",
    "doc.save(word_path)\n",
    "\n",
    "print(f\"Combined Word document saved to: {word_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda44b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
